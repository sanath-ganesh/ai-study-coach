---chunk-0---
Lecture 14: The Efficiency of Algorithms Materials are edited by Prof. Jones Yu fromData Structures and Abstractions with Java, 5th edition. By Frank M. Carrano and Timothy M. Henry. ISBN-13 978-0-13-483169-5 Â© 2019 Pearson Education, Inc. Prof. Chen-Hsiang (Jones) Yu, Ph.D.College of Engineering 2INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§An algorithm is a set of rules that must be followed to solve a specific problem. What is Algorithms? Oxford Learner's Dictionaries 3INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§Computers are faster, have larger memoriesâˆ’So why worry about efficient code?Â§And â€¦ how do we measure efficiency? Why Efficient Code? 4INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§Consider the problem of summingExample Figure 4-1: Three algorithms for computing the sum 1 + 2 + . . . + n for an integer n > 0 Algorithm AAlgorithm BAlgorithm C longsum = 0; for(longi= 1; i<= n; i++)sum = sum + i; sum = 0; for(longi= 1; i<= n; i++) {for(longj = 1; j <= i; j++)sum = sum + 1; } // end forsum = n * (n + 1) / 2; !!"# $ð‘˜=1+2+3+â‹¯+ð‘› 5INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Java code for the three algorithms Example public class Computing { public static void main(String[] args){ long startTime, endTime, totalTime; long n = 100000; //Algorithm A startTime = System.currentTimeMillis(); long sum = 0; for(long i=1;i<=n;i++){ sum = sum + i; } endTime = System.currentTimeMillis(); totalTime = endTime - startTime; System.out.println("sum = " + sum + "; time = " + totalTime + " milliseconds"); //Algorithm B startTime = System.currentTimeMillis(); sum = 0; for(long i=1;i<=n;i++){ for(long j=1;j<=i;j++){ sum = sum + 1; } } endTime = System.currentTimeMillis(); totalTime = endTime - startTime; System.out.println("sum = " + sum + "; time = " + totalTime + " milliseconds"); //Algorithm C startTime = System.currentTimeMillis(); sum = n * (n+1)/2; endTime = System.currentTimeMillis(); totalTime = endTime - startTime; System.out.println("sum = " + sum + "; time = " + totalTime + " milliseconds"); }} Program with Execution Time 7INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Results sum = 5000050000; time = 2 millisecondssum = 5000050000; time = 2028 millisecondssum = 5000050000; time = 0 milliseconds 8INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§An algorithm has both time and space constraints â€“ that is complexityâˆ’Time complexityâˆ’Space complexityÂ§This study is called analysis of algorithms What is â€œbestâ€? 9INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§A basic operation of an algorithmâˆ’The most significant contributor to its total time requirement Counting Basic Operations Figure 4-2: The number of basic operations required by the algorithms in Figure 4-1 Algorithm AAlgorithm BAlgorithm C longsum = 0; for(longi= 1; i<= n; i++)sum = sum + i; sum = 0; for(longi= 1; i<= n; i++) {for(longj = 1; j <= i; j++)sum = sum + 1; } // end forsum = n * (n + 1) / 2; Additonsn n(n + 1)/2 1Multiplications0 0 1Divisions0 0 1Total Basic Operationsn (n2+ n)/2 3 10INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Figure 4-3: The number of basic operations required by the algorithms in Figure 4-1 as a function of n Counting Basic Operations 11INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Figure 4-4: Typical growth-rate functions evaluated at increasing values of n Counting Basic Operations 12INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§For some algorithms, execution time depends only on size of data setÂ§Other algorithms depend on the nature of the data itselfâˆ’Here we seek to know best case, worst case, average case Best, Worst, and Average Cases 13INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§A function ð‘“(ð‘›) is of order at most ð‘”(ð‘›)Â§ð‘“(ð‘›) is ÎŸ(ð‘”ð‘›) - ifâˆ’Positive constants ð‘ and ð‘ exist such that ð‘“(ð‘›)â‰¤ð‘Ã—ð‘”(ð‘›)for allð‘›â‰¥ð‘âˆ’That is, ð‘ Ã— ð‘”(ð‘›) is an upper bound on ð‘“(ð‘›) when ð‘› is sufficiently large. Big Oh Notation 14INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Figure 4-5: An illustration of the definition of Big Oh Big Oh Notation 15INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§Show that 3ð‘›2 + 2ð‘› is ð‘‚(2ð‘›). What values of ð‘ and ð‘ did you use? Exercise 16INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§3ð‘›2 + 2ð‘› â‰¤ 2ð‘› + 2ð‘› = 2 Ã— 2ð‘› when ð‘› â‰¥ 8Â§So 3ð‘›2 + 2ð‘› = ð‘‚(2ð‘›), using ð‘ = 2 and ð‘ = 8 Answer 17INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Identities for Big Oh Notation Big Oh Notation O(k g(n)) = O(g(n)) for a constantk O(g1(n)) + O(g2(n)) = O(g1(n) + g2(n)) O(g1(n)) * O(g2(n)) = O(g1(n) * g2(n)) O(g1(n) + g2(n) + . . . + gm(n)) = O(max(g1(n), g2(n), . . ., gm(n)) O(max(g1(n), g2(n), . . ., gm(n)))= max(O(g1(n)), O(g2(n)), . . ., O(gm(n))) 18INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Complexities of Program Constructs 19INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Figure 4-6: AnO(n) algorithm Picturing Efficiency longsum = 0;for(longi= 1; i<= n; i++)sum = sum + i; 20INFO 6205 -ProgramStructureand AlgorithmsFall 2024Figure 4-7: AnO(n2) algorithm Picturing Efficiency sum = 0;for(longi= 1; i<= n; i++){for(longj = 1; j <= n; j++)sum = sum + 1;} // end for 21INFO 6205 -ProgramStructureand AlgorithmsFall 2024Figure 4-8: AnotherO(n2) algorithm Picturing Efficiency sum = 0;for(longi= 1; i<= n; i++){for(longj = 1; j <= n; j++)sum = sum + 1;} // end for 22INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Figure 4-9: The effect of doubling the problem size on an algorithmâ€™s time requirement Picturing Efficiency Growth-Rate Function for Size n ProblemsGrowth-Rate Function for Size 2n ProblemsEffect on Time Requirement1 1 Nonelog n 1 + log n Negligiblen 2n Doublesnlog n 2nlog n+ 2n Doubles and then adds 2nn2 (2n)2 Quadruplesn3 (2n)3 Multiples by 82n 22n Squares 23INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Figure 4-10: The time required to process one million items by algorithms of various orders at the rate of one million operations per second Picturing Efficiency (cont.) Growth-Rate Function g g(106) / 106 log n 0.0000199 secondsn 1 secondnlog n 19.9 secondsn2 11.6 daysn3 31,709.8 years2n 10301,016years 24INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§A function ð‘“(ð‘›) is of order at least ð‘”(ð‘›) - that is, ð‘“(ð‘›) is Î©(ð‘”(ð‘›)) - if ð‘”(ð‘›) is ÎŸ(ð‘“ð‘›). Â§In other words, ð‘“(ð‘›) is Î©(ð‘”(ð‘›)) ifâˆ’Positive constants ð‘ and ð‘ exist such that ð‘“ð‘›â‰¥ð‘ Ã— ð‘”(ð‘›)for allð‘›â‰¥ð‘âˆ’That is, the time requirement ð‘“(ð‘›) is not smaller
---chunk-1---
+ 1;} // end for 21INFO 6205 -ProgramStructureand AlgorithmsFall 2024Figure 4-8: AnotherO(n2) algorithm Picturing Efficiency sum = 0;for(longi= 1; i<= n; i++){for(longj = 1; j <= n; j++)sum = sum + 1;} // end for 22INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Figure 4-9: The effect of doubling the problem size on an algorithmâ€™s time requirement Picturing Efficiency Growth-Rate Function for Size n ProblemsGrowth-Rate Function for Size 2n ProblemsEffect on Time Requirement1 1 Nonelog n 1 + log n Negligiblen 2n Doublesnlog n 2nlog n+ 2n Doubles and then adds 2nn2 (2n)2 Quadruplesn3 (2n)3 Multiples by 82n 22n Squares 23INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Figure 4-10: The time required to process one million items by algorithms of various orders at the rate of one million operations per second Picturing Efficiency (cont.) Growth-Rate Function g g(106) / 106 log n 0.0000199 secondsn 1 secondnlog n 19.9 secondsn2 11.6 daysn3 31,709.8 years2n 10301,016years 24INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§A function ð‘“(ð‘›) is of order at least ð‘”(ð‘›) - that is, ð‘“(ð‘›) is Î©(ð‘”(ð‘›)) - if ð‘”(ð‘›) is ÎŸ(ð‘“ð‘›). Â§In other words, ð‘“(ð‘›) is Î©(ð‘”(ð‘›)) ifâˆ’Positive constants ð‘ and ð‘ exist such that ð‘“ð‘›â‰¥ð‘ Ã— ð‘”(ð‘›)for allð‘›â‰¥ð‘âˆ’That is, the time requirement ð‘“(ð‘›) is not smaller than ð‘ Ã— ð‘”(ð‘›), its lower bound. Big Omega Notation 25INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§A function ð‘“(ð‘›) is of order ð‘”(ð‘›) - that is, ð‘“(ð‘›) is Î˜(ð‘”ð‘›) - if ð‘“(ð‘›) is ð‘‚(ð‘”(ð‘›)) and ð‘”(ð‘›) is ð‘‚(ð‘“(ð‘›)). Â§Actually, we can say ð‘“(ð‘›) is ð‘‚(ð‘”(ð‘›)) and ð‘“(ð‘›) is Î©(ð‘”(ð‘›)).Â§The time requirement ð‘“(ð‘›) is the same as ð‘”(ð‘›). ð‘ Ã— ð‘”(ð‘›) is both a lower bound and an upper bound on ð‘“(ð‘›).Â§A big theta analysis assures us that the time estimate is as good as possible. Big Theta Notation 26INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§The following algorithm finds out whether an array contains duplicate entries within its first n elements.Â§What is the Big Oh of this algorithm in the worst case? Exercise Algorithm hasDuplicates(array, n)for index = 0 to n âˆ’ 2 for rest = index + 1 to n âˆ’ 1 if (array[index] equals array[rest]) return truereturn false 27INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Â§Letâ€™s tabulate the maximum number of times the inner loop executes for various values of index: Â§As you can see, the maximum number of times the inner loop executes is 1 + 2 + â€¦ + ð‘› âˆ’ 1, which is ð‘› (ð‘› âˆ’ 1) / 2. Thus, the algorithm is ð‘‚(ð‘›2) in the worst case. Answer index Inner Loop Iterations0 n - 11 n - 22 n - 3. . . . . .n - 2 1 28INFO 6205 -ProgramStructureand AlgorithmsFall 2024 Figure 4-11: The time efficiencies of the ADT bag operations for two implementations, expressed in Big Oh notation Efficiency of Implementations of ADT BagOperationFixed-Size ArrayLinkedadd(newEntry) O(1) O(1)remove() O(1) O(1)remove(anEntry) O(1), O(n), O(n) O(1), O(n), O(n)clear() O(n) O(n)getFrequencyOf(anEntry) O(n) O(n)contains(anEntry) O(1), O(n), O(n) O(1), O(n), O(n)toArray() O(n) O(n)getCurrentSize(), isEmpty()O(1) O(1)
